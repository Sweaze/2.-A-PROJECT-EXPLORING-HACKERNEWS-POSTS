{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A PROJECT EXPLORING HACKERNEWS POSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "from csv import reader\n",
    "opened_file=open(\"Datasets/hacker_news.csv\", encoding=\"utf8\")\n",
    "read_file=reader(opened_file)\n",
    "hn=list(read_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']]\n",
      "\n",
      "\n",
      "293120\n"
     ]
    }
   ],
   "source": [
    "print(hn[:5])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(len(hn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "# separating the header row\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139 10158 273822\n"
     ]
    }
   ],
   "source": [
    "# separating the ask and show posts\n",
    "\n",
    "\n",
    "ask_posts =[]\n",
    "\n",
    "show_posts = []\n",
    "\n",
    "other_posts = []\n",
    "\n",
    "for item in hn:\n",
    "    title = item [1]\n",
    "    \n",
    "    \n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(item)\n",
    "        \n",
    "        \n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(item)\n",
    "            \n",
    "    else:\n",
    "        other_posts.append(item)\n",
    "    \n",
    "    \n",
    "print (len(ask_posts), len(show_posts),len(other_posts))    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17'], ['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57'], ['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48'], ['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']]\n",
      "\n",
      "\n",
      "[['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36'], ['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01'], ['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44'], ['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17'], ['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in ask_posts[:5], show_posts[:5]:\n",
    "    \n",
    "    print (item)\n",
    "    \n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of filtering and cleaning the data, we'll remove every comment that does not have any comment from the data set. That would make the dataset easier to work with and more accurate for the analysis we're carrying out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139 10158 273822\n"
     ]
    }
   ],
   "source": [
    "print (len(ask_posts), len(show_posts),len(other_posts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5523 3311 43512\n"
     ]
    }
   ],
   "source": [
    "# Function to filtter \n",
    "\n",
    "def filter_data(dataset):\n",
    "    \n",
    "    cleaned_data=[]\n",
    "    \n",
    "    for item in dataset:\n",
    "        comments = item[4]\n",
    "        \n",
    "        comments = int(comments)\n",
    "        \n",
    "        if comments>1:\n",
    "            cleaned_data.append(item)\n",
    "            \n",
    "    dataset=cleaned_data\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "ask_posts = filter_data(ask_posts)\n",
    "\n",
    "show_posts = filter_data(show_posts)\n",
    "\n",
    "other_posts = filter_data(other_posts)\n",
    "\n",
    "\n",
    "print (len(ask_posts), len(show_posts),len(other_posts)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a beautiful and effective function. Ordinarily, we should have cleaned the entire dataset in this manner before splitting it up, but this also give new insight. DOing this also drastically reduced the size of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.946949121854065\n"
     ]
    }
   ],
   "source": [
    "# To determine which types of posts get more engagement\n",
    "\n",
    "total_ask_comments = 0\n",
    "\n",
    "\n",
    "for item in ask_posts:\n",
    "    num_comments= item[4]\n",
    "    \n",
    "    num_comments = int(num_comments)\n",
    "    \n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comment = total_ask_comments/len(ask_posts)\n",
    "\n",
    "\n",
    "print (avg_ask_comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.46239806704923\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "\n",
    "for item in show_posts:\n",
    "    num_comments= item[4]\n",
    "    \n",
    "    num_comments = int(num_comments)\n",
    "    \n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comment = total_show_comments/len(show_posts)\n",
    "\n",
    "\n",
    "print (avg_show_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, it is seen that 'ask hn' posts get slightly more comments than 'show hn' post. We'll therefore focus our remaining analysis on 'ask hn' posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'02': 2954,\n",
       " '01': 2048,\n",
       " '22': 3315,\n",
       " '21': 4420,\n",
       " '19': 3859,\n",
       " '17': 5464,\n",
       " '15': 18421,\n",
       " '14': 4884,\n",
       " '13': 7193,\n",
       " '11': 2754,\n",
       " '10': 2967,\n",
       " '09': 1429,\n",
       " '07': 1560,\n",
       " '16': 4384,\n",
       " '08': 2321,\n",
       " '03': 2109,\n",
       " '00': 2231,\n",
       " '23': 2243,\n",
       " '20': 4392,\n",
       " '18': 4793,\n",
       " '12': 4184,\n",
       " '04': 2328,\n",
       " '06': 1550,\n",
       " '05': 1795}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the amount of ask posts created during each hour of day and the number of comments received.\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "\n",
    "\n",
    "for item in ask_posts:\n",
    "    \n",
    "    result_list.append(\n",
    "        [item[6], int(item[4])])\n",
    "    \n",
    "counts_by_hour= {}\n",
    "\n",
    "\n",
    "comments_by_hour = {}\n",
    "\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for each_row in result_list:\n",
    "    date = each_row[0]\n",
    "    comment = each_row[1]\n",
    "    time = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    if time in counts_by_hour:\n",
    "        comments_by_hour[time] += comment\n",
    "        counts_by_hour[time] += 1\n",
    "    else:\n",
    "        comments_by_hour[time] = comment\n",
    "        counts_by_hour[time] = 1\n",
    "        \n",
    "comments_by_hour             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to calculate the average number of comments per post for posts created during each hour of the day using the created dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 15.967567567567567],\n",
       " ['01', 11.252747252747254],\n",
       " ['22', 14.41304347826087],\n",
       " ['21', 13.516819571865444],\n",
       " ['19', 11.873846153846154]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Calculate the average amount of comments `Ask HN` posts created at each hour of the day receive.\n",
    "\n",
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    \n",
    "    avg_by_hour.append([hour, comments_by_hour[hour] / counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour[:5]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sorting and Printing Values from a List of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50.7465564738292, '15'], [26.251824817518248, '13'], [18.678571428571427, '12']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print (sorted_swap[:3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "15:00: 50.75 average comments per post\n",
      "13:00: 26.25 average comments per post\n",
      "12:00: 18.68 average comments per post\n",
      "10:00: 17.15 average comments per post\n",
      "17:00: 17.02 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Sort the values and print the the 5 hours with the highest average comments.\n",
    "\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"),avg\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
